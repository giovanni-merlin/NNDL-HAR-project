{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "937f9c44-0e99-440b-b57c-47210908e5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import math as mt\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "452199c2-ef7c-4243-97fd-b8f11a45f216",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_windows_antennas(csi_list, labels_list, sample_length, stride_length, remove_mean=False):\n",
    "    csi_matrix_stride = []\n",
    "    labels_stride = []\n",
    "    for i in range(len(labels_list)):\n",
    "        csi_i = csi_list[i]\n",
    "        label_i = labels_list[i]\n",
    "        len_csi = csi_i.shape[2]\n",
    "        for ii in range(0, len_csi - sample_length, stride_length):\n",
    "            csi_wind = csi_i[:, :, ii:ii + sample_length, ...]\n",
    "            if remove_mean:\n",
    "                csi_mean = np.mean(csi_wind, axis=2, keepdims=True)\n",
    "                csi_wind = csi_wind - csi_mean\n",
    "            csi_matrix_stride.append(csi_wind)\n",
    "            labels_stride.append(label_i)\n",
    "    return csi_matrix_stride, labels_stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9893eb05-8659-4805-8889-342baeef67ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_number(lab, csi_label_dict):\n",
    "    lab_num = np.argwhere(np.asarray(csi_label_dict) == lab)[0][0]\n",
    "    return lab_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "948823da-f2b4-4557-89b5-df4f87151c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_init = './doppler_traces/' #Directory of data\n",
    "subdir_init = 'S1a,S1b,S1c' #Sub-directories\n",
    "sample_lengths_init = 31 #Number of packets in a sample\n",
    "sliding_init = 1 #Number of packet for sliding operations\n",
    "windows_length_init = 340 #Number of samples per window\n",
    "stride_lengths_init = 30 #Number of samples to stride\n",
    "labels_activities_init = 'E,L,W,R,J' #Labels of the activities to be considered\n",
    "n_tot_init = 4 #Number of streams * number of antennas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ad4fc2e-015c-4d4d-bd3e-f88006ad80c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_activities = labels_activities_init\n",
    "csi_label_dict = []\n",
    "for lab_act in labels_activities.split(','):\n",
    "    csi_label_dict.append(lab_act)\n",
    "\n",
    "activities = np.asarray(labels_activities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "132b7f9c-df88-4221-aa83-5651aff0df03",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tot = n_tot_init\n",
    "num_packets = sample_lengths_init  # 51\n",
    "middle = int(np.floor(num_packets / 2))\n",
    "list_subdir = subdir_init  # string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74d58870-7234-456d-be97-86bab7445171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S1a_E_stream_0\n",
      "S1a_E_stream_1\n",
      "S1a_E_stream_2\n",
      "S1a_E_stream_3\n",
      "S1a_J1_stream_0\n",
      "S1a_J1_stream_1\n",
      "S1a_J1_stream_2\n",
      "S1a_J1_stream_3\n",
      "S1a_J2_stream_0\n",
      "S1a_J2_stream_1\n",
      "S1a_J2_stream_2\n",
      "S1a_J2_stream_3\n",
      "S1a_L_stream_0\n",
      "S1a_L_stream_1\n",
      "S1a_L_stream_2\n",
      "S1a_L_stream_3\n",
      "S1a_R_stream_0\n",
      "S1a_R_stream_1\n",
      "S1a_R_stream_2\n",
      "S1a_R_stream_3\n",
      "S1a_W_stream_0\n",
      "S1a_W_stream_1\n",
      "S1a_W_stream_2\n",
      "S1a_W_stream_3\n",
      "S1b_E_stream_0\n",
      "S1b_E_stream_1\n",
      "S1b_E_stream_2\n",
      "S1b_E_stream_3\n",
      "S1b_J1_stream_0\n",
      "S1b_J1_stream_1\n",
      "S1b_J1_stream_2\n",
      "S1b_J1_stream_3\n",
      "S1b_J2_stream_0\n",
      "S1b_J2_stream_1\n",
      "S1b_J2_stream_2\n",
      "S1b_J2_stream_3\n",
      "S1b_L_stream_0\n",
      "S1b_L_stream_1\n",
      "S1b_L_stream_2\n",
      "S1b_L_stream_3\n",
      "S1b_R_stream_0\n",
      "S1b_R_stream_1\n",
      "S1b_R_stream_2\n",
      "S1b_R_stream_3\n",
      "S1b_W_stream_0\n",
      "S1b_W_stream_1\n",
      "S1b_W_stream_2\n",
      "S1b_W_stream_3\n",
      "ERROR - shapes mismatch\n",
      "1799  and  1800.0 \n",
      "\n",
      "ERROR - shapes mismatch\n",
      "556  and  557.0 \n",
      "\n",
      "ERROR - shapes mismatch\n",
      "543  and  545.0 \n",
      "\n",
      "S1c_E_stream_0\n",
      "S1c_E_stream_1\n",
      "S1c_E_stream_2\n",
      "S1c_E_stream_3\n",
      "S1c_J1_stream_0\n",
      "S1c_J1_stream_1\n",
      "S1c_J1_stream_2\n",
      "S1c_J1_stream_3\n",
      "S1c_J2_stream_0\n",
      "S1c_J2_stream_1\n",
      "S1c_J2_stream_2\n",
      "S1c_J2_stream_3\n",
      "S1c_L_stream_0\n",
      "S1c_L_stream_1\n",
      "S1c_L_stream_2\n",
      "S1c_L_stream_3\n",
      "S1c_R_stream_0\n",
      "S1c_R_stream_1\n",
      "S1c_R_stream_2\n",
      "S1c_R_stream_3\n",
      "S1c_W_stream_0\n",
      "S1c_W_stream_1\n",
      "S1c_W_stream_2\n",
      "S1c_W_stream_3\n"
     ]
    }
   ],
   "source": [
    "for subdir in list_subdir.split(','):\n",
    "    exp_dir = dir_init + subdir + '/'\n",
    "\n",
    "    path_train = exp_dir + 'train_antennas_' + str(activities)\n",
    "    path_val = exp_dir + 'val_antennas_' + str(activities)\n",
    "    path_test = exp_dir + 'test_antennas_' + str(activities)\n",
    "    paths = [path_train, path_val, path_test]\n",
    "    for pat in paths:\n",
    "        if os.path.exists(pat):\n",
    "            remove_files = glob.glob(pat + '/*')\n",
    "            for f in remove_files:\n",
    "                os.remove(f)\n",
    "        else:\n",
    "            os.mkdir(pat)\n",
    "\n",
    "    path_complete = exp_dir + 'complete_antennas_' + str(activities)\n",
    "    if os.path.exists(path_complete):\n",
    "        shutil.rmtree(path_complete)\n",
    "\n",
    "    names = []\n",
    "    all_files = os.listdir(exp_dir)\n",
    "    for i in range(len(all_files)):\n",
    "        if all_files[i].startswith('S'):\n",
    "            names.append(all_files[i][:-4])\n",
    "    names.sort()\n",
    "\n",
    "    csi_matrices = []\n",
    "    labels = []\n",
    "    lengths = []\n",
    "    label = 'null'\n",
    "    prev_label = label\n",
    "    csi_matrix = []\n",
    "    processed = False\n",
    "    for i_name, name in enumerate(names):\n",
    "        if i_name % n_tot == 0 and i_name != 0 and processed:\n",
    "            ll = csi_matrix[0].shape[1]\n",
    "\n",
    "            for i_ant in range(1, n_tot):\n",
    "                if ll != csi_matrix[i_ant].shape[1]:\n",
    "                    break\n",
    "            lengths.append(ll)\n",
    "            csi_matrices.append(np.asarray(csi_matrix))\n",
    "            labels.append(label)\n",
    "            csi_matrix = []\n",
    "\n",
    "        label = name[4]\n",
    "\n",
    "        if label not in csi_label_dict:\n",
    "            processed = False\n",
    "            continue\n",
    "        processed = True\n",
    "\n",
    "        print(name)\n",
    "\n",
    "        label = convert_to_number(label, csi_label_dict)\n",
    "        if i_name % n_tot == 0:\n",
    "            prev_label = label\n",
    "        elif label != prev_label:\n",
    "            print('error in ' + str(name))\n",
    "            break\n",
    "\n",
    "        name_file = exp_dir + name + '.txt'\n",
    "        with open(name_file, \"rb\") as fp:  # Unpickling\n",
    "            stft_sum_1 = pickle.load(fp)\n",
    "\n",
    "        stft_sum_1_mean = stft_sum_1 - np.mean(stft_sum_1, axis=0, keepdims=True)\n",
    "\n",
    "        csi_matrix.append(stft_sum_1_mean.T)\n",
    "\n",
    "    error = False\n",
    "    if processed:\n",
    "        # for the last block\n",
    "        if len(csi_matrix) < n_tot:\n",
    "            print('error in ' + str(name))\n",
    "        ll = csi_matrix[0].shape[1]\n",
    "\n",
    "        for i_ant in range(1, n_tot):\n",
    "            if ll != csi_matrix[i_ant].shape[1]:\n",
    "                print('error in ' + str(name))\n",
    "                error = True\n",
    "        if not error:\n",
    "            lengths.append(ll)\n",
    "            csi_matrices.append(np.asarray(csi_matrix))\n",
    "            labels.append(label)\n",
    "\n",
    "    if not error:\n",
    "        lengths = np.asarray(lengths)\n",
    "        length_min = np.min(lengths)\n",
    "\n",
    "        csi_train = []\n",
    "        csi_val = []\n",
    "        csi_test = []\n",
    "        length_train = []\n",
    "        length_val = []\n",
    "        length_test = []\n",
    "        for i in range(len(labels)):\n",
    "            ll = lengths[i]\n",
    "            train_len = int(np.floor(ll * 0.6))\n",
    "            length_train.append(train_len)\n",
    "            csi_train.append(csi_matrices[i][:, :, :train_len])\n",
    "\n",
    "            start_val = train_len + mt.ceil(num_packets/sliding_init)\n",
    "            val_len = int(np.floor(ll * 0.2))\n",
    "            length_val.append(val_len)\n",
    "            csi_val.append(csi_matrices[i][:, :, start_val:start_val + val_len])\n",
    "\n",
    "            start_test = start_val + val_len + mt.ceil(num_packets/sliding_init)\n",
    "            length_test.append(ll - val_len - train_len - 2*mt.ceil(num_packets/sliding_init))\n",
    "            csi_test.append(csi_matrices[i][:, :, start_test:])\n",
    "\n",
    "        window_length = windows_length_init  # number of windows considered\n",
    "        stride_length = stride_lengths_init\n",
    "\n",
    "        list_sets_name = ['train', 'val', 'test']\n",
    "        list_sets = [csi_train, csi_val, csi_test]\n",
    "        list_sets_lengths = [length_train, length_val, length_test]\n",
    "\n",
    "        for set_idx in range(3):\n",
    "            csi_matrices_set, labels_set = create_windows_antennas(list_sets[set_idx], labels, window_length,\n",
    "                                                                    stride_length, remove_mean=False)\n",
    "\n",
    "            num_windows = np.floor((np.asarray(list_sets_lengths[set_idx]) - window_length) / stride_length + 1)\n",
    "            if not len(csi_matrices_set) == np.sum(num_windows):\n",
    "                print('ERROR - shapes mismatch')\n",
    "                print(len(csi_matrices_set), ' and ', np.sum(num_windows), '\\n')\n",
    "\n",
    "            names_set = []\n",
    "            suffix = '.txt'\n",
    "            for ii in range(len(csi_matrices_set)):\n",
    "                name_file = exp_dir + list_sets_name[set_idx] + '_antennas_' + str(activities) + '/' + \\\n",
    "                            str(ii) + suffix\n",
    "                names_set.append(name_file)\n",
    "                with open(name_file, \"wb\") as fp:  # Pickling\n",
    "                    pickle.dump(csi_matrices_set[ii], fp)\n",
    "            name_labels = exp_dir + '/labels_' + list_sets_name[set_idx] + '_antennas_' + str(activities) + suffix\n",
    "            with open(name_labels, \"wb\") as fp:  # Pickling\n",
    "                pickle.dump(labels_set, fp)\n",
    "            name_f = exp_dir + '/files_' + list_sets_name[set_idx] + '_antennas_' + str(activities) + suffix\n",
    "            with open(name_f, \"wb\") as fp:  # Pickling\n",
    "                pickle.dump(names_set, fp)\n",
    "            name_f = exp_dir + '/num_windows_' + list_sets_name[set_idx] + '_antennas_' + str(activities) + suffix\n",
    "            with open(name_f, \"wb\") as fp:  # Pickling\n",
    "                pickle.dump(num_windows, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cda519-aad6-41c6-a562-9f17a671609f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
