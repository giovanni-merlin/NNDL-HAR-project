{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de59843b-8773-4307-951a-c76b4b6aa2e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Copyright (C) 2022 Francesca Meneghello\\n    contact: meneghello@dei.unipd.it\\n    This program is free software: you can redistribute it and/or modify\\n    it under the terms of the GNU General Public License as published by\\n    the Free Software Foundation, either version 3 of the License, or\\n    (at your option) any later version.\\n    This program is distributed in the hope that it will be useful,\\n    but WITHOUT ANY WARRANTY; without even the implied warranty of\\n    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\\n    GNU General Public License for more details.\\n    You should have received a copy of the GNU General Public License\\n    along with this program.  If not, see <https://www.gnu.org/licenses/>.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Copyright (C) 2022 Francesca Meneghello\n",
    "    contact: meneghello@dei.unipd.it\n",
    "    This program is free software: you can redistribute it and/or modify\n",
    "    it under the terms of the GNU General Public License as published by\n",
    "    the Free Software Foundation, either version 3 of the License, or\n",
    "    (at your option) any later version.\n",
    "    This program is distributed in the hope that it will be useful,\n",
    "    but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "    GNU General Public License for more details.\n",
    "    You should have received a copy of the GNU General Public License\n",
    "    along with this program.  If not, see <https://www.gnu.org/licenses/>.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cac8964-8444-4522-bff0-a9a855420fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utilities import *\n",
    "from torch.nn import Module, Sequential, Conv2d, BatchNorm2d, ReLU, MaxPool2d, AvgPool2d, Linear, Dropout, CrossEntropyLoss\n",
    "from torch.optim import SGD, Adam\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e9d693e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_init = './doppler_traces/' #Directory of data\n",
    "subdirs_init = 'S1a' #Subdirs for training\n",
    "feature_length_init = 100 #Length along the feature dimension (height)\n",
    "sample_length_init = 340 #Length along the time dimension (width)\n",
    "channels_init = 1 #Number of channels\n",
    "batch_size_init = 32 #Number of samples in a batch\n",
    "num_tot_init = 4 #Number of antenna * number of spatial streams\n",
    "name_base_init = 'single_ant' #Name base for the files\n",
    "activities_init = 'E,L,W,R,J' #Activities to be considered\n",
    "bandwidth_init = 80 #Bandwidth in [MHz] to select the subcarriers, can be 20, 40, 80 (default 80)\n",
    "sub_band_init = 1 #Sub_band idx in [1, 2, 3, 4] for 20 MHz, [1, 2] for 40 MHz (default 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c91245a-f916-4f76-8529-79850130f7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50ef5a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1e80a693d50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "# fix this\n",
    "seed = 203\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d800e987",
   "metadata": {},
   "source": [
    "#### Create datasets for training, validation and test\n",
    "Generate the datasets using the ``create dataset single`` function which returns a DataLoader object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2aa315e0-c34d-40aa-960b-678d106d2b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "bandwidth = bandwidth_init\n",
    "sub_band = sub_band_init\n",
    "\n",
    "csi_act = activities_init\n",
    "activities = []\n",
    "for lab_act in csi_act.split(','):\n",
    "    activities.append(lab_act)\n",
    "activities = np.asarray(activities)\n",
    "\n",
    "name_base = name_base_init\n",
    "if os.path.exists(name_base + '_' + str(csi_act) + '_cache_train.data-00000-of-00001'):\n",
    "    os.remove(name_base + '_' + str(csi_act) + '_cache_train.data-00000-of-00001')\n",
    "    os.remove(name_base + '_' + str(csi_act) + '_cache_train.index')\n",
    "if os.path.exists(name_base + '_' + str(csi_act) + '_cache_val.data-00000-of-00001'):\n",
    "    os.remove(name_base + '_' + str(csi_act) + '_cache_val.data-00000-of-00001')\n",
    "    os.remove(name_base + '_' + str(csi_act) + '_cache_val.index')\n",
    "if os.path.exists(name_base + '_' + str(csi_act) + '_cache_train_test.data-00000-of-00001'):\n",
    "    os.remove(name_base + '_' + str(csi_act) + '_cache_train_test.data-00000-of-00001')\n",
    "    os.remove(name_base + '_' + str(csi_act) + '_cache_train_test.index')\n",
    "if os.path.exists(name_base + '_' + str(csi_act) + '_cache_test.data-00000-of-00001'):\n",
    "    os.remove(name_base + '_' + str(csi_act) + '_cache_test.data-00000-of-00001')\n",
    "    os.remove(name_base + '_' + str(csi_act) + '_cache_test.index')\n",
    "\n",
    "subdirs_training = subdirs_init  # string\n",
    "labels_train = []\n",
    "all_files_train = []\n",
    "labels_val = []\n",
    "all_files_val = []\n",
    "labels_test = []\n",
    "all_files_test = []\n",
    "sample_length = sample_length_init\n",
    "feature_length = feature_length_init\n",
    "channels = channels_init\n",
    "num_antennas = num_tot_init\n",
    "input_shape = (num_antennas, sample_length, feature_length, channels)\n",
    "input_network = (sample_length, feature_length, channels)\n",
    "batch_size = batch_size_init\n",
    "output_shape = activities.shape[0]\n",
    "labels_considered = np.arange(output_shape)\n",
    "activities = activities[labels_considered]\n",
    "\n",
    "suffix = '.txt'\n",
    "\n",
    "for sdir in subdirs_training.split(','):\n",
    "    exp_save_dir = dir_init + sdir + '/'\n",
    "    \n",
    "    dir_train = dir_init + sdir + '/train_antennas_' + str(csi_act) + '/'\n",
    "    name_labels = dir_init + sdir + '/labels_train_antennas_' + str(csi_act) + suffix\n",
    "    with open(name_labels, \"rb\") as fp:  # Unpickling\n",
    "        labels_train.extend(pickle.load(fp))\n",
    "    name_f = dir_init + sdir + '/files_train_antennas_' + str(csi_act) + suffix\n",
    "    with open(name_f, \"rb\") as fp:  # Unpickling\n",
    "        all_files_train.extend(pickle.load(fp))\n",
    "\n",
    "    dir_val = dir_init + sdir + '/val_antennas_' + str(csi_act) + '/'\n",
    "    name_labels = dir_init + sdir + '/labels_val_antennas_' + str(csi_act) + suffix\n",
    "    with open(name_labels, \"rb\") as fp:  # Unpickling\n",
    "        labels_val.extend(pickle.load(fp))\n",
    "    name_f = dir_init + sdir + '/files_val_antennas_' + str(csi_act) + suffix\n",
    "    with open(name_f, \"rb\") as fp:  # Unpickling\n",
    "        all_files_val.extend(pickle.load(fp))\n",
    "\n",
    "    dir_test = dir_init + sdir + '/test_antennas_' + str(csi_act) + '/'\n",
    "    name_labels = dir_init + sdir + '/labels_test_antennas_' + str(csi_act) + suffix\n",
    "    with open(name_labels, \"rb\") as fp:  # Unpickling\n",
    "        labels_test.extend(pickle.load(fp))\n",
    "    name_f = dir_init + sdir + '/files_test_antennas_' + str(csi_act) + suffix\n",
    "    with open(name_f, \"rb\") as fp:  # Unpickling\n",
    "        all_files_test.extend(pickle.load(fp))\n",
    "\n",
    "\n",
    "file_train_selected = [all_files_train[idx] for idx in range(len(labels_train)) if labels_train[idx] in\n",
    "                        labels_considered]\n",
    "labels_train_selected = [labels_train[idx] for idx in range(len(labels_train)) if labels_train[idx] in\n",
    "                            labels_considered]\n",
    "\n",
    "file_train_selected_expanded, labels_train_selected_expanded, stream_ant_train = \\\n",
    "    expand_antennas(file_train_selected, labels_train_selected, num_antennas)\n",
    "\n",
    "# create the batches\n",
    "name_cache = name_base + '_' + str(csi_act) + '_cache_train'\n",
    "dataset_csi_train = create_dataset_single(file_train_selected_expanded, labels_train_selected_expanded,\n",
    "                                            stream_ant_train, input_network, batch_size,\n",
    "                                            shuffle=True, cache_file=name_cache)\n",
    "\n",
    "file_val_selected = [all_files_val[idx] for idx in range(len(labels_val)) if labels_val[idx] in\n",
    "                        labels_considered]\n",
    "labels_val_selected = [labels_val[idx] for idx in range(len(labels_val)) if labels_val[idx] in\n",
    "                        labels_considered]\n",
    "\n",
    "file_val_selected_expanded, labels_val_selected_expanded, stream_ant_val = \\\n",
    "    expand_antennas(file_val_selected, labels_val_selected, num_antennas)\n",
    "\n",
    "name_cache_val = name_base + '_' + str(csi_act) + '_cache_val'\n",
    "dataset_csi_val = create_dataset_single(file_val_selected_expanded, labels_val_selected_expanded,\n",
    "                                        stream_ant_val, input_network, batch_size,\n",
    "                                        shuffle=False, cache_file=name_cache_val)\n",
    "\n",
    "file_test_selected = [all_files_test[idx] for idx in range(len(labels_test)) if labels_test[idx] in\n",
    "                        labels_considered]\n",
    "labels_test_selected = [labels_test[idx] for idx in range(len(labels_test)) if labels_test[idx] in\n",
    "                        labels_considered]\n",
    "\n",
    "file_test_selected_expanded, labels_test_selected_expanded, stream_ant_test = \\\n",
    "    expand_antennas(file_test_selected, labels_test_selected, num_antennas)\n",
    "\n",
    "name_cache_test = name_base + '_' + str(csi_act) + '_cache_test'\n",
    "dataset_csi_test = create_dataset_single(file_test_selected_expanded, labels_test_selected_expanded,\n",
    "                                            stream_ant_test, input_network, batch_size,\n",
    "                                            shuffle=False, cache_file=name_cache_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e073aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7232"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "226*32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74224e5c",
   "metadata": {},
   "source": [
    "#### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a60af2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be54d2dd",
   "metadata": {},
   "source": [
    "``Conv2d_bn`` helper module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb608ee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass Conv2d_bn(Module):\\n    def __init__(self, in_filters, out_filters, kernel_size, strides, padding):\\n        super().__init__()\\n        self.conv = nn.Conv2d(in_filters, out_filters, kernel_size=kernel_size, stride=strides, padding=padding)\\n        self.relu = nn.ReLU()\\n\\n    def _init_weights(self, module):\\n        if isinstance(module, torch.nn.Conv2d):\\n            torch.nn.init.xavier_uniform_(module.weight)\\n            if module.bias is not None:\\n                module.bias.data.zero_()\\n\\n    def forward(self, x):\\n        x = self.conv(x)\\n        return self.relu(x)\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "class Conv2d_bn(Module):\n",
    "    def __init__(self, in_filters, out_filters, kernel_size, strides, padding):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_filters, out_filters, kernel_size=kernel_size, stride=strides, padding=padding)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, torch.nn.Conv2d):\n",
    "            torch.nn.init.xavier_uniform_(module.weight)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return self.relu(x)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad42840d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"class Conv2d_bn(nn.Module):\\n    def init(self, in_filters, out_filters, kernel_size, strides=(1, 1), padding='same'):\\n        super(Conv2d_bn, self).init()\\n        \\n        # Calcola il padding asimmetrico necessario per 'same' padding\\n        if padding == 'same':\\n            if isinstance(kernel_size, tuple):\\n                padding_val = [(k - 1) // 2 for k in kernel_size]\\n                padding_extra = [(k - 1) % 2 for k in kernel_size]\\n            else:\\n                padding_val = (kernel_size - 1) // 2\\n                padding_extra = (kernel_size - 1) % 2\\n        else:\\n            padding_val = 0\\n            padding_extra = 0\\n\\n        self.conv = nn.Conv2d(in_filters, out_filters, kernel_size=kernel_size, stride=strides, padding=padding_val)\\n        self.relu = nn.ReLU()\\n        self.padding = padding_val\\n        self.padding_extra = padding_extra\\n\\n    def forward(self, x):\\n        if self.padding_extra != 0:\\n            x = F.pad(x, [0, self.padding_extra[1], 0, self.padding_extra[0]])\\n        x = self.conv(x)\\n        return self.relu(x)\\n    \""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"class Conv2d_bn(nn.Module):\n",
    "    def init(self, in_filters, out_filters, kernel_size, strides=(1, 1), padding='same'):\n",
    "        super(Conv2d_bn, self).init()\n",
    "        \n",
    "        # Calcola il padding asimmetrico necessario per 'same' padding\n",
    "        if padding == 'same':\n",
    "            if isinstance(kernel_size, tuple):\n",
    "                padding_val = [(k - 1) // 2 for k in kernel_size]\n",
    "                padding_extra = [(k - 1) % 2 for k in kernel_size]\n",
    "            else:\n",
    "                padding_val = (kernel_size - 1) // 2\n",
    "                padding_extra = (kernel_size - 1) % 2\n",
    "        else:\n",
    "            padding_val = 0\n",
    "            padding_extra = 0\n",
    "\n",
    "        self.conv = nn.Conv2d(in_filters, out_filters, kernel_size=kernel_size, stride=strides, padding=padding_val)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.padding = padding_val\n",
    "        self.padding_extra = padding_extra\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.padding_extra != 0:\n",
    "            x = F.pad(x, [0, self.padding_extra[1], 0, self.padding_extra[0]])\n",
    "        x = self.conv(x)\n",
    "        return self.relu(x)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ca57529",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math as m\n",
    "\n",
    "class Conv2d_bn(nn.Module):\n",
    "    def __init__(self, in_filters, out_filters, kernel_size, in_dimension=(0,0), strides=(1, 1), padding='valid'):\n",
    "        super(Conv2d_bn, self).__init__()\n",
    "\n",
    "        if isinstance(kernel_size, tuple):\n",
    "            kernel_height, kernel_width = kernel_size\n",
    "        else:\n",
    "            kernel_height = kernel_width = kernel_size\n",
    "\n",
    "        if isinstance(strides, tuple):\n",
    "            stride_height, stride_width = strides\n",
    "        else:\n",
    "            stride_height = stride_width = strides\n",
    "\n",
    "        in_height, in_width = in_dimension\n",
    "\n",
    "        # Calcola il padding totale necessario per mantenere le dimensioni in uscita uguali a quelle in ingresso\n",
    "        if padding == 'same':\n",
    "            # Calcolo per altezza (height)\n",
    "            total_padding_height = (m.ceil(in_height/stride_height) - 1)*stride_height - in_height + kernel_height #kernel_height - stride_height\n",
    "            pad_top = total_padding_height // 2\n",
    "            pad_bottom = total_padding_height - pad_top\n",
    "            \n",
    "            # Calcolo per larghezza (width)\n",
    "            total_padding_width = (m.ceil(in_width/stride_width) - 1)*stride_width - in_width + kernel_width\n",
    "            pad_left = total_padding_width // 2\n",
    "            pad_right = total_padding_width - pad_left\n",
    "\n",
    "            self.padding = (pad_left, pad_right, pad_top, pad_bottom)\n",
    "        else:\n",
    "            self.padding = (0, 0, 0, 0)\n",
    "\n",
    "        self.conv = nn.Conv2d(in_filters, out_filters, kernel_size=kernel_size, stride=strides, padding=0)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "            if isinstance(module, torch.nn.Linear):\n",
    "                torch.nn.init.xavier_uniform_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    module.bias.data.zero_()\n",
    "            if isinstance(module, torch.nn.Conv2d):\n",
    "                torch.nn.init.xavier_uniform_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    module.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Applica il padding asimmetrico se necessario\n",
    "        if self.padding != (0, 0, 0, 0):\n",
    "            x = F.pad(x, self.padding)\n",
    "        x = self.conv(x)\n",
    "        return self.relu(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1f64ca",
   "metadata": {},
   "source": [
    "``Reduction`` block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29fa00ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reduction(Module):\n",
    "\n",
    "    def __init__(self, in_filters):\n",
    "        super().__init__()\n",
    "        self.max_pool = MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.central_block = Conv2d_bn(in_filters=in_filters, out_filters=5, kernel_size=2, strides=2, padding=\"valid\")\n",
    "        self.right_block =  Sequential(\n",
    "            Conv2d_bn(in_filters=in_filters, in_dimension=(340,100), out_filters=3, kernel_size=1, strides=1, padding=\"same\"), \n",
    "            Conv2d_bn(in_filters=3, in_dimension=(340,100), out_filters=6, kernel_size=2, strides=1, padding=\"same\"),  \n",
    "            Conv2d_bn(in_filters=6, in_dimension=(340,100), out_filters=9, kernel_size=4, strides=2, padding=\"same\"), #for the mthe padding is same also here?!\n",
    "        )\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, torch.nn.Linear):\n",
    "            torch.nn.init.xavier_uniform_(module.weight)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        if isinstance(module, torch.nn.Conv2d):\n",
    "            torch.nn.init.xavier_uniform_(module.weight)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_1 = self.max_pool(x)\n",
    "        x_2 = self.central_block(x)\n",
    "        x_3 = self.right_block(x)\n",
    "        x = torch.cat([x_1, x_2, x_3], axis=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b301c38",
   "metadata": {},
   "source": [
    "``Inception`` network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7618d320",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception(Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.reduction = Reduction(1)\n",
    "        self.conv = Conv2d_bn(in_filters=15, in_dimension=(170,50), out_filters=3, kernel_size=1, strides=1, padding=\"same\") #padding?\n",
    "        self.drop = Dropout(0.2)\n",
    "        self.classification_layer = Linear(25500, 5) #170*50*3\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.reduction(x)\n",
    "        x = self.conv(x)\n",
    "        x = t.flatten(x, start_dim=1) # keep the batch dimension \n",
    "        #x = x.reshape(x.shape[0], -1, 1536).mean(axis=1)\n",
    "        x = self.drop(x)\n",
    "        y = self.classification_layer(x)\n",
    "        return y\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, torch.nn.Linear):\n",
    "            torch.nn.init.xavier_uniform_(module.weight)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        if isinstance(module, torch.nn.Conv2d):\n",
    "            torch.nn.init.xavier_uniform_(module.weight)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd81670",
   "metadata": {},
   "source": [
    "#### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afeadf78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 1.2350497245788574: 100%|██████████| 226/226 [00:10<00:00, 21.68it/s]\n",
      "100%|██████████| 70/70 [00:01<00:00, 38.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.2028717994689941, accuracy: 0.6171734929084778\n",
      "Saved Model\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7369858622550964: 100%|██████████| 226/226 [00:07<00:00, 28.54it/s]\n",
      "100%|██████████| 70/70 [00:01<00:00, 56.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.7822629809379578, accuracy: 0.7093023061752319\n",
      "Saved Model\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.28052955865859985: 100%|██████████| 226/226 [00:07<00:00, 28.74it/s]\n",
      "100%|██████████| 70/70 [00:01<00:00, 52.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.41575887799263, accuracy: 0.865384578704834\n",
      "Saved Model\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.22427324950695038: 100%|██████████| 226/226 [00:07<00:00, 28.25it/s]\n",
      "100%|██████████| 70/70 [00:01<00:00, 56.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.2668212056159973, accuracy: 0.9190518856048584\n",
      "Saved Model\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.12467873096466064: 100%|██████████| 226/226 [00:07<00:00, 30.57it/s]\n",
      "100%|██████████| 70/70 [00:01<00:00, 59.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.18342886865139008, accuracy: 0.9838998317718506\n",
      "Saved Model\n",
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.18980565667152405: 100%|██████████| 226/226 [00:07<00:00, 28.79it/s]\n",
      "100%|██████████| 70/70 [00:01<00:00, 59.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.13976706564426422, accuracy: 0.9883720874786377\n",
      "Saved Model\n",
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.07242290675640106: 100%|██████████| 226/226 [00:07<00:00, 30.05it/s] \n",
      "100%|██████████| 70/70 [00:01<00:00, 60.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.09611623734235764, accuracy: 0.9928443431854248\n",
      "Saved Model\n",
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.05373568460345268: 100%|██████████| 226/226 [00:07<00:00, 30.26it/s] \n",
      "100%|██████████| 70/70 [00:01<00:00, 58.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.07256010174751282, accuracy: 0.9950804710388184\n",
      "Saved Model\n",
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.060010481625795364: 100%|██████████| 226/226 [00:07<00:00, 29.80it/s]\n",
      "100%|██████████| 70/70 [00:01<00:00, 59.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.05546842887997627, accuracy: 0.9959749579429626\n",
      "Saved Model\n",
      "Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.04174988716840744: 100%|██████████| 226/226 [00:07<00:00, 30.22it/s] \n",
      "100%|██████████| 70/70 [00:01<00:00, 58.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.04278154671192169, accuracy: 0.9968693852424622\n",
      "Saved Model\n",
      "Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.042277708649635315: 100%|██████████| 226/226 [00:07<00:00, 29.43it/s]\n",
      "100%|██████████| 70/70 [00:01<00:00, 59.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.03403265029191971, accuracy: 0.9977638721466064\n",
      "Saved Model\n",
      "Epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.04153492674231529: 100%|██████████| 226/226 [00:07<00:00, 29.76it/s] \n",
      "100%|██████████| 70/70 [00:01<00:00, 60.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.030606994405388832, accuracy: 0.9941860437393188\n",
      "Saved Model\n",
      "Epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.010415034368634224: 100%|██████████| 226/226 [00:07<00:00, 30.23it/s]\n",
      "100%|██████████| 70/70 [00:01<00:00, 59.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.02782973274588585, accuracy: 0.9973165988922119\n",
      "Saved Model\n",
      "Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.013240893371403217: 100%|██████████| 226/226 [00:07<00:00, 30.22it/s] \n",
      "100%|██████████| 70/70 [00:01<00:00, 61.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.022900721058249474, accuracy: 0.9968693852424622\n",
      "Saved Model\n",
      "Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.008776070550084114: 100%|██████████| 226/226 [00:07<00:00, 29.84it/s] \n",
      "100%|██████████| 70/70 [00:01<00:00, 56.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.014485652558505535, accuracy: 0.9991055130958557\n",
      "Saved Model\n",
      "Epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.002994983457028866: 100%|██████████| 226/226 [00:07<00:00, 30.48it/s] \n",
      "100%|██████████| 70/70 [00:01<00:00, 58.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.01274050772190094, accuracy: 0.9977638721466064\n",
      "Saved Model\n",
      "Epoch: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.025668540969491005: 100%|██████████| 226/226 [00:07<00:00, 29.85it/s] \n",
      "100%|██████████| 70/70 [00:01<00:00, 59.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.01235970575362444, accuracy: 0.9959749579429626\n",
      "Saved Model\n",
      "Epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.002197671914473176: 100%|██████████| 226/226 [00:07<00:00, 29.92it/s] \n",
      "100%|██████████| 70/70 [00:01<00:00, 59.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.011139645241200924, accuracy: 0.9964221715927124\n",
      "Saved Model\n",
      "Epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.006154429633170366: 100%|██████████| 226/226 [00:07<00:00, 29.94it/s] \n",
      "100%|██████████| 70/70 [00:01<00:00, 61.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.008842785842716694, accuracy: 0.9995527267456055\n",
      "Saved Model\n",
      "Epoch: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.003508040215820074: 100%|██████████| 226/226 [00:07<00:00, 30.51it/s] \n",
      "100%|██████████| 70/70 [00:01<00:00, 61.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.007998553104698658, accuracy: 0.9991055130958557\n",
      "Saved Model\n",
      "Epoch: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0036851242184638977: 100%|██████████| 226/226 [00:07<00:00, 30.67it/s]\n",
      "100%|██████████| 70/70 [00:01<00:00, 59.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.007352740969508886, accuracy: 0.998658299446106\n",
      "Saved Model\n",
      "Epoch: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.002657083561643958: 100%|██████████| 226/226 [00:07<00:00, 29.91it/s] \n",
      "100%|██████████| 70/70 [00:01<00:00, 59.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.006964307278394699, accuracy: 0.998658299446106\n",
      "Saved Model\n",
      "Epoch: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0007493382436223328: 100%|██████████| 226/226 [00:07<00:00, 30.07it/s] \n",
      "100%|██████████| 70/70 [00:01<00:00, 58.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.005816420074552298, accuracy: 0.9991055130958557\n",
      "Saved Model\n",
      "Epoch: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0024841581471264362: 100%|██████████| 226/226 [00:07<00:00, 30.28it/s] \n",
      "100%|██████████| 70/70 [00:01<00:00, 59.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.006598660722374916, accuracy: 0.9977638721466064\n",
      "Epoch: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0011713751591742039: 100%|██████████| 226/226 [00:07<00:00, 30.27it/s] \n",
      "100%|██████████| 70/70 [00:01<00:00, 57.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.005699195433408022, accuracy: 0.998658299446106\n",
      "Saved Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = Inception()\n",
    "opt = Adam(model.parameters(), lr=0.0001)\n",
    "loss_fn = CrossEntropyLoss() # by default reduction=\"mean\" i.e. the output is a scalar\n",
    "#device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "epochs=25\n",
    "best_val = np.inf\n",
    "train_error = []\n",
    "validation_error = []\n",
    "for epoch in range(epochs):\n",
    "    train_loss = []\n",
    "    model.train()\n",
    "    print(f\"Epoch: {epoch+1}\")\n",
    "    iterator = tqdm(dataset_csi_train) # iterate over the batches\n",
    "    for batch_x, batch_y in iterator:\n",
    "        batch_x = batch_x.to(device) # batch with the inputs\n",
    "        batch_y = batch_y.to(device) # batch with the labels\n",
    "        batch_y = t.squeeze(batch_y, dim=1)\n",
    "\n",
    "        y_pred = model(batch_x) \n",
    "\n",
    "        loss = loss_fn(y_pred, batch_y)\n",
    " \n",
    "        opt.zero_grad() \n",
    "        loss.backward() #how is it bound to the model?\n",
    "        opt.step()\n",
    "        train_loss.append(loss.detach().cpu().numpy())\n",
    "        iterator.set_description(f\"Train loss: {loss.detach().cpu().numpy()}\")\n",
    "    train_error.append(np.mean(train_loss))\n",
    "\n",
    "    # validation\n",
    "    model.eval() # what does this change?\n",
    "    with torch.no_grad():\n",
    "        predictions = []\n",
    "        true = []\n",
    "        for batch_x, batch_y in tqdm(dataset_csi_val):\n",
    "            batch_x = batch_x.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "            batch_y = t.squeeze(batch_y, dim=1)\n",
    "\n",
    "            y_pred = model(batch_x)\n",
    "\n",
    "            predictions.append(y_pred)\n",
    "            true.append(batch_y)\n",
    "        predictions = torch.cat(predictions, axis=0) # concatenate the predictions for all batches\n",
    "        true = torch.cat(true, axis=0)\n",
    "        val_loss = loss_fn(predictions, true)\n",
    "        validation_error.append(val_loss.detach().cpu().numpy())\n",
    "\n",
    "        val_acc = (torch.softmax(predictions, dim=1).argmax(dim=1) == true).float().mean()\n",
    "        ###REMEMBER TO ADD CONFUSION MATRIX, KEEPING IN MIND TO PASS FROM CUDA TO CPU\n",
    "        #conf_matrix_val = confusion_matrix(true, torch.softmax(predictions, dim=1).argmax(dim=1))\n",
    "        #if true in argsort[:N] per top-N score?\n",
    "        print(f\"loss: {val_loss}, accuracy: {val_acc}\")\n",
    "\n",
    "    if val_loss < best_val:\n",
    "        print(\"Saved Model\")\n",
    "        torch.save(model.state_dict(), \"model.pt\")\n",
    "        best_val = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e4ba5cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(train_error, label=\"Train loss\")\n",
    "plt.plot(validation_error, label=\"Validation loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eea8fec",
   "metadata": {},
   "source": [
    "Now we proceed with the test of our trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a23ffa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [00:02<00:00, 33.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.009355204179883003, accuracy: 0.9981718464351006\n",
      "torch.Size([2188, 5])\n"
     ]
    }
   ],
   "source": [
    "model.eval() # what does this change?\n",
    "with torch.no_grad():\n",
    "    predictions = []\n",
    "    true = []\n",
    "    for batch_x, batch_y in tqdm(dataset_csi_test):\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "        batch_y = t.squeeze(batch_y, dim=1)\n",
    "\n",
    "        y_pred = model(batch_x)\n",
    "\n",
    "        predictions.append(y_pred)\n",
    "        true.append(batch_y)\n",
    "    predictions = torch.cat(predictions, axis=0) # concatenate the predictions for all batches\n",
    "    true = torch.cat(true, axis=0)\n",
    "    test_loss = loss_fn(predictions, true)\n",
    "    true = true.detach().cpu()\n",
    "    test_prediction_list = torch.softmax(predictions, dim=1).detach().cpu()\n",
    "    test_labels_pred = test_prediction_list.argmax(dim=1)\n",
    "    test_acc = (test_labels_pred == true).float().mean()\n",
    "    conf_matrix = confusion_matrix(true, test_labels_pred)\n",
    "    precision, recall, fscore, _ = precision_recall_fscore_support(true,\n",
    "                                                                   test_labels_pred,\n",
    "                                                                   labels=labels_considered)\n",
    "    accuracy = accuracy_score(true, test_labels_pred)\n",
    "    #if true in argsort[:N] per top-N score?\n",
    "    #print(f\"loss: {test_loss}, accuracy: {test_acc}\")\n",
    "    print(f\"loss: {test_loss}, accuracy: {accuracy}\")\n",
    "    print(test_prediction_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4521a76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge antennas test\n",
    "labels_true_merge = np.array(labels_test_selected)\n",
    "pred_max_merge = np.zeros_like(labels_test_selected)\n",
    "for i_lab in range(len(labels_test_selected)):\n",
    "    pred_antennas = test_prediction_list[i_lab * num_antennas:(i_lab + 1) * num_antennas, :].numpy()\n",
    "    #print(pred_antennas.shape)\n",
    "    lab_merge_max = np.argmax(np.sum(pred_antennas, axis=0))\n",
    "    #print(np.sum(pred_antennas, axis=0).shape)\n",
    "\n",
    "    pred_max_antennas = test_labels_pred[i_lab * num_antennas:(i_lab + 1) * num_antennas]\n",
    "    lab_unique, count = np.unique(pred_max_antennas, return_counts=True)\n",
    "    lab_max_merge = -1\n",
    "    if lab_unique.shape[0] > 1:\n",
    "        count_argsort = np.flip(np.argsort(count))\n",
    "        count_sort = count[count_argsort]\n",
    "        lab_unique_sort = lab_unique[count_argsort]\n",
    "        if count_sort[0] == count_sort[1] or lab_unique.shape[0] > 2:  # ex aequo between two labels\n",
    "            lab_max_merge = lab_merge_max\n",
    "        else:\n",
    "            lab_max_merge = lab_unique_sort[0]\n",
    "    else:\n",
    "        lab_max_merge = lab_unique[0]\n",
    "    pred_max_merge[i_lab] = lab_max_merge\n",
    "\n",
    "conf_matrix_max_merge = confusion_matrix(labels_true_merge, pred_max_merge, labels=labels_considered)\n",
    "precision_max_merge, recall_max_merge, fscore_max_merge, _ = \\\n",
    "    precision_recall_fscore_support(labels_true_merge, pred_max_merge, labels=labels_considered)\n",
    "accuracy_max_merge = accuracy_score(labels_true_merge, pred_max_merge)\n",
    "\n",
    "metrics_matrix_dict = {'conf_matrix': conf_matrix,\n",
    "                        'accuracy_single': accuracy,\n",
    "                        'precision_single': precision,\n",
    "                        'recall_single': recall,\n",
    "                        'fscore_single': fscore,\n",
    "                        'conf_matrix_max_merge': conf_matrix_max_merge,\n",
    "                        'accuracy_max_merge': accuracy_max_merge,\n",
    "                        'precision_max_merge': precision_max_merge,\n",
    "                        'recall_max_merge': recall_max_merge,\n",
    "                        'fscore_max_merge': fscore_max_merge}\n",
    "\n",
    "name_file = './outputs/test_' + str(csi_act) + '_' + subdirs_training + '_band_' + str(bandwidth) + '_subband_' + \\\n",
    "            str(sub_band) + suffix\n",
    "with open(name_file, \"wb\") as fp:  # Pickling\n",
    "    pickle.dump(metrics_matrix_dict, fp)\n",
    "\n",
    "# impact of the number of antennas\n",
    "one_antenna = [[0], [1], [2], [3]]\n",
    "two_antennas = [[0, 1], [0, 2], [0, 3], [1, 2], [1, 3], [2, 3]]\n",
    "three_antennas = [[0, 1, 2], [0, 1, 3], [0, 2, 3], [1, 2, 3]]\n",
    "four_antennas = [[0, 1, 2, 3]]\n",
    "seq_ant_list = [one_antenna, two_antennas, three_antennas, four_antennas]\n",
    "average_accuracy_change_num_ant = np.zeros((num_antennas,))\n",
    "average_fscore_change_num_ant = np.zeros((num_antennas,))\n",
    "labels_true_merge = np.array(labels_test_selected)\n",
    "for ant_n in range(num_antennas):\n",
    "    seq_ant = seq_ant_list[ant_n]\n",
    "    num_seq = len(seq_ant)\n",
    "    for seq_n in range(num_seq):\n",
    "        pred_max_merge = np.zeros((len(labels_test_selected),))\n",
    "        ants_selected = seq_ant[seq_n]\n",
    "        for i_lab in range(len(labels_test_selected)):\n",
    "            pred_antennas = test_prediction_list[i_lab * num_antennas:(i_lab + 1) * num_antennas, :].numpy()\n",
    "            pred_antennas = pred_antennas[ants_selected, :]\n",
    "\n",
    "            lab_merge_max = np.argmax(np.sum(pred_antennas, axis=0))\n",
    "\n",
    "            pred_max_antennas = test_labels_pred[i_lab * num_antennas:(i_lab + 1) * num_antennas]\n",
    "            pred_max_antennas = pred_max_antennas[ants_selected]\n",
    "            lab_unique, count = np.unique(pred_max_antennas, return_counts=True)\n",
    "            lab_max_merge = -1\n",
    "            if lab_unique.shape[0] > 1:\n",
    "                count_argsort = np.flip(np.argsort(count))\n",
    "                count_sort = count[count_argsort]\n",
    "                lab_unique_sort = lab_unique[count_argsort]\n",
    "                if count_sort[0] == count_sort[1] or lab_unique.shape[0] > ant_n - 1:  # ex aequo between two labels\n",
    "                    lab_max_merge = lab_merge_max\n",
    "                else:\n",
    "                    lab_max_merge = lab_unique_sort[0]\n",
    "            else:\n",
    "                lab_max_merge = lab_unique[0]\n",
    "            pred_max_merge[i_lab] = lab_max_merge\n",
    "\n",
    "        _, _, fscore_max_merge, _ = precision_recall_fscore_support(labels_true_merge, pred_max_merge,\n",
    "                                                                    labels=[0, 1, 2, 3, 4])\n",
    "        accuracy_max_merge = accuracy_score(labels_true_merge, pred_max_merge)\n",
    "\n",
    "        average_accuracy_change_num_ant[ant_n] += accuracy_max_merge\n",
    "        average_fscore_change_num_ant[ant_n] += np.mean(fscore_max_merge)\n",
    "\n",
    "    average_accuracy_change_num_ant[ant_n] = average_accuracy_change_num_ant[ant_n] / num_seq\n",
    "    average_fscore_change_num_ant[ant_n] = average_fscore_change_num_ant[ant_n] / num_seq\n",
    "\n",
    "metrics_matrix_dict = {'average_accuracy_change_num_ant': average_accuracy_change_num_ant,\n",
    "                        'average_fscore_change_num_ant': average_fscore_change_num_ant}\n",
    "\n",
    "name_file = './outputs/change_number_antennas_test_' + str(csi_act) + '_' + subdirs_training + '_band_' + \\\n",
    "            str(bandwidth) + '_subband_' + str(sub_band) + '.txt'\n",
    "with open(name_file, \"wb\") as fp:  # Pickling\n",
    "    pickle.dump(metrics_matrix_dict, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcd9c55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d669940",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4231434e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c470c5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5b78a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target tensor: tensor([4, 3, 1])\n",
      "target tensor: tensor([[0.0808, 0.2741, 0.1219, 0.4518, 0.0714],\n",
      "        [0.1243, 0.3703, 0.0939, 0.2450, 0.1664],\n",
      "        [0.2252, 0.1695, 0.1627, 0.2942, 0.1484]])\n"
     ]
    }
   ],
   "source": [
    "# Example of target with class indices\n",
    "# non capisco come funzioni tbh\n",
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "print(\"target tensor:\", target)\n",
    "output = loss(input, target)\n",
    "output.backward()\n",
    "\n",
    "# Example of target with class probabilities\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.randn(3, 5).softmax(dim=1)\n",
    "print(\"target tensor:\", target)\n",
    "output = loss(input, target)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa297d0",
   "metadata": {},
   "source": [
    "Now we proceed testing our model in the other sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a796256e",
   "metadata": {},
   "outputs": [],
   "source": [
    "subdirs_init = 'S2a' #Subdirs for testing our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a06336f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 611/611 [00:11<00:00, 54.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.9845441579818726, accuracy: 0.9307432432432432\n",
      "torch.Size([19536, 5])\n",
      "(4884,) (4884,)\n",
      "accuracy 0.9721539721539721\n",
      "fscore [1.         1.         0.89291339 0.9581112  0.83018868]\n",
      "[[1663    0    0    0    0]\n",
      " [   0 1691    0    0    0]\n",
      " [   0    0  567   55    0]\n",
      " [   0    0    0  629    0]\n",
      " [   0    0   81    0  198]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\feder\\anaconda3\\envs\\nnml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\feder\\anaconda3\\envs\\nnml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\feder\\anaconda3\\envs\\nnml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\feder\\anaconda3\\envs\\nnml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\feder\\anaconda3\\envs\\nnml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "csi_act = activities_init\n",
    "activities = []\n",
    "for lab_act in csi_act.split(','):\n",
    "    activities.append(lab_act)\n",
    "activities = np.asarray(activities)\n",
    "\n",
    "suffix = '.txt'\n",
    "\n",
    "name_base = name_base_init\n",
    "if os.path.exists(name_base + '_' + str(csi_act) + '_cache_complete.data-00000-of-00001'):\n",
    "    os.remove(name_base + '_' + str(csi_act) + '_cache_complete.data-00000-of-00001')\n",
    "    os.remove(name_base + '_' + str(csi_act) + '_cache_complete.index')\n",
    "\n",
    "subdirs_complete = subdirs_init  # string\n",
    "labels_complete = []\n",
    "all_files_complete = []\n",
    "sample_length = sample_length_init\n",
    "feature_length = feature_length_init\n",
    "channels = channels_init\n",
    "num_antennas = num_tot_init\n",
    "input_shape = (num_antennas, sample_length, feature_length, channels)\n",
    "input_network = (sample_length, feature_length, channels)\n",
    "batch_size = batch_size_init\n",
    "output_shape = activities.shape[0]\n",
    "labels_considered = np.arange(output_shape)\n",
    "activities = activities[labels_considered]\n",
    "\n",
    "for sdir in subdirs_complete.split(','):\n",
    "    exp_save_dir = dir_init + sdir + '/'\n",
    "    dir_complete = dir_init + sdir + '/complete_antennas_' + str(csi_act) + '/'\n",
    "    name_labels = dir_init + sdir + '/labels_complete_antennas_' + str(csi_act) + suffix\n",
    "    with open(name_labels, \"rb\") as fp:  # Unpickling\n",
    "        labels_complete.extend(pickle.load(fp))\n",
    "    name_f = dir_init + sdir + '/files_complete_antennas_' + str(csi_act) + suffix\n",
    "    with open(name_f, \"rb\") as fp:  # Unpickling\n",
    "        all_files_complete.extend(pickle.load(fp))\n",
    "\n",
    "file_complete_selected = [all_files_complete[idx] for idx in range(len(labels_complete)) if labels_complete[idx] in\n",
    "                            labels_considered]\n",
    "labels_complete_selected = [labels_complete[idx] for idx in range(len(labels_complete)) if labels_complete[idx] in\n",
    "                            labels_considered]\n",
    "\n",
    "file_complete_selected_expanded, labels_complete_selected_expanded, stream_ant_complete = \\\n",
    "    expand_antennas(file_complete_selected, labels_complete_selected, num_antennas)\n",
    "\n",
    "dataset_csi_complete = create_dataset_single(file_complete_selected_expanded, labels_complete_selected_expanded,\n",
    "                                                stream_ant_complete, input_network, batch_size, shuffle=False,\n",
    "                                                cache_file=name_base + '_' + str(csi_act) + '_cache_complete')\n",
    "\n",
    "\n",
    "model.eval() # what does this change?\n",
    "with torch.no_grad():\n",
    "    predictions = []\n",
    "    true = []\n",
    "    for batch_x, batch_y in tqdm(dataset_csi_complete):\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "        batch_y = t.squeeze(batch_y, dim=1)\n",
    "\n",
    "        y_pred = model(batch_x)\n",
    "\n",
    "        predictions.append(y_pred)\n",
    "        true.append(batch_y)\n",
    "    predictions = torch.cat(predictions, axis=0) # concatenate the predictions for all batches\n",
    "    true = torch.cat(true, axis=0)\n",
    "    complete_loss = loss_fn(predictions, true)\n",
    "    true = true.detach().cpu()\n",
    "    complete_prediction_list = torch.softmax(predictions, dim=1).detach().cpu()\n",
    "    complete_labels_pred = complete_prediction_list.argmax(dim=1)\n",
    "    complete_acc = (complete_labels_pred == true).float().mean()\n",
    "    conf_matrix = confusion_matrix(true, complete_labels_pred)\n",
    "    precision, recall, fscore, _ = precision_recall_fscore_support(true,\n",
    "                                                                   complete_labels_pred,\n",
    "                                                                   labels=labels_considered)\n",
    "    accuracy = accuracy_score(true, complete_labels_pred)\n",
    "    #if true in argsort[:N] per top-N score?\n",
    "    #print(f\"loss: {test_loss}, accuracy: {test_acc}\")\n",
    "    print(f\"loss: {complete_loss}, accuracy: {accuracy}\")\n",
    "    print(complete_prediction_list.shape)\n",
    "\n",
    "\n",
    "# merge antennas\n",
    "labels_true_merge = np.array(labels_complete_selected)\n",
    "pred_max_merge = np.zeros_like(labels_complete_selected)\n",
    "for i_lab in range(len(labels_complete_selected)):\n",
    "    pred_antennas = complete_prediction_list[i_lab*num_antennas:(i_lab+1)*num_antennas, :].numpy()\n",
    "    sum_pred = np.sum(pred_antennas, axis=0)\n",
    "    lab_merge_max = np.argmax(sum_pred)\n",
    "\n",
    "    pred_max_antennas = complete_labels_pred[i_lab*num_antennas:(i_lab+1)*num_antennas]\n",
    "    lab_unique, count = np.unique(pred_max_antennas, return_counts=True)\n",
    "    lab_max_merge = -1\n",
    "    if lab_unique.shape[0] > 1:\n",
    "        count_argsort = np.flip(np.argsort(count))\n",
    "        count_sort = count[count_argsort]\n",
    "        lab_unique_sort = lab_unique[count_argsort]\n",
    "        if count_sort[0] == count_sort[1] or lab_unique.shape[0] > 2:  # ex aequo between two labels\n",
    "            lab_max_merge = lab_merge_max\n",
    "        else:\n",
    "            lab_max_merge = lab_unique_sort[0]\n",
    "    else:\n",
    "        lab_max_merge = lab_unique[0]\n",
    "    pred_max_merge[i_lab] = lab_max_merge\n",
    "\n",
    "print(labels_true_merge.shape, pred_max_merge.shape)\n",
    "\n",
    "conf_matrix_max_merge = confusion_matrix(labels_true_merge, pred_max_merge, labels=labels_considered)\n",
    "precision_max_merge, recall_max_merge, fscore_max_merge, _ = \\\n",
    "    precision_recall_fscore_support(labels_true_merge, pred_max_merge, labels=labels_considered)\n",
    "accuracy_max_merge = accuracy_score(labels_true_merge, pred_max_merge)\n",
    "\n",
    "metrics_matrix_dict = {'conf_matrix': conf_matrix,\n",
    "                        'accuracy_single': accuracy,\n",
    "                        'precision_single': precision,\n",
    "                        'recall_single': recall,\n",
    "                        'fscore_single': fscore,\n",
    "                        'conf_matrix_max_merge': conf_matrix_max_merge,\n",
    "                        'accuracy_max_merge': accuracy_max_merge,\n",
    "                        'precision_max_merge': precision_max_merge,\n",
    "                        'recall_max_merge': recall_max_merge,\n",
    "                        'fscore_max_merge': fscore_max_merge}\n",
    "\n",
    "name_file = './outputs/complete_different_' + str(csi_act) + '_' + subdirs_complete + '_band_' + str(bandwidth) \\\n",
    "            + '_subband_' + str(sub_band) + suffix\n",
    "with open(name_file, \"wb\") as fp:  # Pickling\n",
    "    pickle.dump(metrics_matrix_dict, fp)\n",
    "print('accuracy', accuracy_max_merge)\n",
    "print('fscore', fscore_max_merge)\n",
    "print(conf_matrix_max_merge)\n",
    "\n",
    "# impact of the number of antennas\n",
    "one_antenna = [[0], [1], [2], [3]]\n",
    "two_antennas = [[0, 1], [0, 2], [0, 3], [1, 2], [1, 3], [2, 3]]\n",
    "three_antennas = [[0, 1, 2], [0, 1, 3], [0, 2, 3], [1, 2, 3]]\n",
    "four_antennas = [[0, 1, 2, 3]]\n",
    "seq_ant_list = [one_antenna, two_antennas, three_antennas, four_antennas]\n",
    "average_accuracy_change_num_ant = np.zeros((num_antennas, ))\n",
    "average_fscore_change_num_ant = np.zeros((num_antennas, ))\n",
    "labels_true_merge = np.array(labels_complete_selected)\n",
    "for ant_n in range(num_antennas):\n",
    "    seq_ant = seq_ant_list[ant_n]\n",
    "    num_seq = len(seq_ant)\n",
    "    for seq_n in range(num_seq):\n",
    "        pred_max_merge = np.zeros((len(labels_complete_selected), ))\n",
    "        ants_selected = seq_ant[seq_n]\n",
    "        for i_lab in range(len(labels_complete_selected)):\n",
    "            pred_antennas = complete_prediction_list[i_lab * num_antennas:(i_lab + 1) * num_antennas, :].numpy()\n",
    "            pred_antennas = pred_antennas[ants_selected, :]\n",
    "\n",
    "            lab_merge_max = np.argmax(np.sum(pred_antennas, axis=0))\n",
    "\n",
    "            pred_max_antennas = complete_labels_pred[i_lab * num_antennas:(i_lab + 1) * num_antennas]\n",
    "            pred_max_antennas = pred_max_antennas[ants_selected]\n",
    "            lab_unique, count = np.unique(pred_max_antennas, return_counts=True)\n",
    "            lab_max_merge = -1\n",
    "            if lab_unique.shape[0] > 1:\n",
    "                count_argsort = np.flip(np.argsort(count))\n",
    "                count_sort = count[count_argsort]\n",
    "                lab_unique_sort = lab_unique[count_argsort]\n",
    "                if count_sort[0] == count_sort[1] or lab_unique.shape[0] > ant_n - 1:  # ex aequo between two labels\n",
    "                    lab_max_merge = lab_merge_max\n",
    "                else:\n",
    "                    lab_max_merge = lab_unique_sort[0]\n",
    "            else:\n",
    "                lab_max_merge = lab_unique[0]\n",
    "            pred_max_merge[i_lab] = lab_max_merge\n",
    "\n",
    "        _, _, fscore_max_merge, _ = precision_recall_fscore_support(labels_true_merge, pred_max_merge,\n",
    "                                                                    labels=[0, 1, 2, 3, 4])\n",
    "        accuracy_max_merge = accuracy_score(labels_true_merge, pred_max_merge)\n",
    "\n",
    "        average_accuracy_change_num_ant[ant_n] += accuracy_max_merge\n",
    "        average_fscore_change_num_ant[ant_n] += np.mean(fscore_max_merge)\n",
    "\n",
    "    average_accuracy_change_num_ant[ant_n] = average_accuracy_change_num_ant[ant_n] / num_seq\n",
    "    average_fscore_change_num_ant[ant_n] = average_fscore_change_num_ant[ant_n] / num_seq\n",
    "\n",
    "metrics_matrix_dict = {'average_accuracy_change_num_ant': average_accuracy_change_num_ant,\n",
    "                        'average_fscore_change_num_ant': average_fscore_change_num_ant}\n",
    "\n",
    "name_file = './outputs/change_number_antennas_complete_different_' + str(csi_act) + '_' + subdirs_complete + \\\n",
    "            '_band_' + str(bandwidth) + '_subband_' + str(sub_band) + '.txt'\n",
    "with open(name_file, \"wb\") as fp:  # Pickling\n",
    "    pickle.dump(metrics_matrix_dict, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a5f11b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b647a8d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538da2a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f80379",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecea467",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77fdb300",
   "metadata": {},
   "source": [
    "#### Ratatuja"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedd5cbb",
   "metadata": {},
   "source": [
    "#### considerazioni\n",
    "- riguardo al padding per avere la corretta concatenazione: alla fine del Reduction block i vari branch devono essere concatenati, i.e. i layer vengono messi in successione lungo la terza dimensione. Per questo è necessario che abbiano tutti la stessa shape (che è facilmente fissata dal MaxPool). Il fattore determinante per ridurre la dimensione del layer è la stride: a stride n corrisponde una riduzione circa di un fattore n (al momento n=2). Una volta fissate la stride e la dimensione del kernel, per ottenere esattamente la shape desiderata è necessario scegliere accuratamente il padding. Pytorch supporta vari metodi per specificare il padding: \"same\", \"valid\" (no padding), int o tupla. Con stride=1 il padding per i vari lati è calcolato automaticamente in modo da ottenere in outout la stessa shape dell'input! Quindi ci è molto utile, però funziona solamente per stride=1. Con tupla si può specificare qual è il padding ma solo nelle due direzioni, i.e. NON SUPPPORTA PADDING ASIMMETRICO. In generale possiamo specificare per i singoli casi qual è il padding necessario, ma ciò non è esauriente. Nel caso in cui abbiamo stride>1, se è necessario padding asimmetrico, dobbiamo aggiungerlo manualmente probabilmente con un metodo di functional ad hoc...\n",
    "\n",
    "- nel right branch: i layer hanno kernel di dimensione crescente (FOV di dimensione crescente) per classificare features più estese man mano che si va più in profondità. Anche il numero delle feature maps cresce con la profondità.\\\n",
    "L'ultimo layer è quello che dimezza le dimensioni.\n",
    "\n",
    "- durante il training: 1. calcolare i label predetti per una batch 2. calcolare la loss per una batch 3. effettuare la backpropagation con loss.backward() per ottenere i gradienti della loss rispetto ai prametri della NN 4. ottimizzare i parametri con un ottimizzatore con opt.step(), che usa i gradienti calcolati al punto precedente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbf02da",
   "metadata": {},
   "source": [
    "#### domande\n",
    "- perchè vi sono esattamente 3 layer nel right branch? Cambia significativamente se si modifica il numero?\n",
    "- come fa l'ottimizzatore a leggere i gradienti?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a21250c",
   "metadata": {},
   "source": [
    "#### TODO\n",
    "- eliminare ``cache file\" nella\n",
    "- provare a modificare l'ordine dei layers nell'ultimo branch per vedere se cambia? Forse inutile perchè perdo comprimerei l'informazione prima"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d894acd",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
